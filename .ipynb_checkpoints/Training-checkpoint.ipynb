{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the  Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "from pyspark.ml.feature import StopWordsRemover,Tokenizer, HashingTF, Word2Vec, IDF,NGram\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"yelp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"gs://bdl2021_final_project/yelp_train.json\" # path of train data file\n",
    "yelpDF = spark.read.json(path).select('review_id','text','stars') # reading selected columns data\n",
    "yelpDF.printSchema() # schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7863924"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelpDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yelpDF = yelpDF.withColumn(\"text_raw\", f.regexp_replace(\"text\", \"[^a-zA-Z0-9\\s+\\']\", \"\")) # stripping special characters\n",
    "yelpDF = yelpDF.withColumn(\"text_split\", f.split(f.trim(\"text_raw\"),\"\\s+\")) # splitting clean text into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- text_raw: string (nullable = true)\n",
      " |-- text_split: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yelpDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Pipeline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol=\"text_split\", outputCol=\"clean_words\") # removing the stop words\n",
    "hashingTF = HashingTF(inputCol=\"clean_words\", outputCol=\"rawFeatures\", numFeatures=10000) # making features\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5)\n",
    "lr = LogisticRegression(labelCol=\"stars\",featuresCol=\"features\") # logistic regression\n",
    "\n",
    "(trainingData, testData) = yelpDF.randomSplit([0.8, 0.2]) # splitting train and test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.683716\n",
      "Test F1 = 0.66193\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[remover,hashingTF,idf,lr]) # pipeline with 4 stages as said above\n",
    "\n",
    "pipeline_model = pipeline.fit(trainingData) #fitting the model\n",
    "predictions = pipeline_model.transform(testData) #predictions on test data\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"stars\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions,{evaluator.metricName: \"accuracy\"}) # accuracy calculation\n",
    "print(\"Test Accuracy = %g\" % (accuracy))\n",
    "\n",
    "f1 = evaluator.evaluate(predictions,{evaluator.metricName: \"f1\"}) # f1 score calculation\n",
    "print(\"Test F1 = %g\" % (f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
